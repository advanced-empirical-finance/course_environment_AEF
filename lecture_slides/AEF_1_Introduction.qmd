---
title: "Advanced Empirical Finance: Topics and Data Science"
author: "Stefan Voigt"
institute: "University of Copenhagen and Danish Finance Institute"
date: today
date-format: "[Spring] YYYY"
format: beamer
pdf-engine: lualatex

theme: metropolis
fontsize: 10pt
mainfont: Fira Sans
monofont: Source Code Pro
monofontoptions: 
  - Scale=0.9
mathfont: firamath

knitr:
  opts_chunk: 
    size: "tiny"
    fig.width: 8
    fig.height: 4
    fig.align: "center"
    out.width: "60%"
    R.options:
      tibble.print_max : 4
      tibble.print_min : 4
      formatR.indent: 2
      digits : 3
      crayon.enabled: FALSE

execute:
  echo: TRUE
  cache: FALSE
  eval: TRUE
  message: FALSE
  warning: FALSE

header-includes: |-
  \metroset{progressbar=frametitle} 
  \usepackage{graphicx} 
  \usepackage{booktabs} 
  \usepackage{amsmath,amsfonts,amssymb} 
  \usepackage{listings} 
  \setbeamercolor{progress bar}{fg=red} 
  \setbeamercolor{frametitle}{fg=black,bg=white} 
  \setbeamercolor{background canvas}{bg=white} 
  \usepackage{hyperref} 
  \hypersetup{colorlinks=false}
  \setbeamertemplate{itemize/enumerate body begin}{\footnotesize}
---

```{r}
#| include: false
source("pre_session_script.R")
```

```{python}
#| include: false
from plotnine import theme_set, theme, theme_bw
theme_set(theme_bw() + theme(legend_position="bottom"))
```

## Welcome!

![](figures/fearless_girl.jpg){width=80% fig-align="center"}

### First: The fine print

- What is this course about?
- How is this course organized?
- Set-up R, Python, Quarto, and RStudio
- Tidy coding principles

# Course introduction

## What is empirical Finance? What is data science?

### Empirical Finance

- Broadly: Empirical Finance includes any empirical work in financial economics or financial econometrics
- Financial markets provide vast data to inform financial decisions: Can we predict investment risks? What determines asset prices? Are markets efficient?

### Data Science

- Plethora of buzzwords: big data, Machine learning, AI
- The less intriguing reality: How to extract knowledge from typically very large or unstructured data?
- This course: We incorporate skills from computer science, mathematics, statistics, and information visualization, projected on economics theory
- *You can (try to) do tech without statistics, but you cannot do it without coding*

**(How) can state-of-the-art methods improve financial decision making?**

## Topics of this course

- Optimal portfolio allocation (in theory and with real data)
- Backtesting of portfolio strategies
- Risk premia and factor selection
- Machine learning toolbox for financial forecasting
- Risk management and volatility estimation
- High-frequency econometrics

### At the end of the course, you should

- Understand the current state of research in empirical asset pricing matters
- Have your own ready-to-use state-of-the-art toolbox for empirical analysis
- Recognize the value of reproducible research (and know how to conduct a reproducible analysis)

## Objectives and tasks

### (Guided) coding assignments
- Plan, perform, and implement data-science applications from scratch
- Master and carry through relevant asset pricing models and solutions in new, unpredictable, and complex contexts
- In plain words: *Learn how to use tidy coding principles in R or Python for empirical projects by writing code and conducting your research!*

### The lecture is based on very recent academic papers
- We discuss and criticize multifactor asset pricing models, portfoliometrics, and high-frequency econometrics
- The reading list is available on Absalon
- Be prepared to discuss the literature during the lecture!

## This course within the KU curriculum

### AEF aims to close the gap between some core finance courses at KU

- Financial Decision Making
- Financial Econometrics A

### Related courses to consider

- Introduction to Programming and Numerical Analysis
- Various seminars in (applied) Finance
- Master thesis in Finance track (Do you consider writing your thesis on empirical Finance? [Check my homepage](https://www.voigtstefan.me/post/supervision/) and get in touch *early*!)

# Administration

## Team and communication

- Stefan (\href{mailto:stefan.voigt@econ.ku.dk}{stefan.voigt@econ.ku.dk}, \href{www.voigtstefan.me}{www.voigtstefan.me})
- Weekly office hours - a chance to ask questions! (Thursdays, 1.30 - 2.30)
- Teaching assistant: Pedro (\href{mailto::pego@di.ku.dk}{pego@di.ku.dk})
- Pedro moderates Absalon discussions, but it is **your responsibility** to actively engage in the exchange of ideas, code, and knowledge!
- We provide all exercises, slides, data, and other documents via Absalon
- **Remainder of the team**: all the peers around you - connect and help each other out!

### Lecture hall

- Lecture and Exercise class 2: CSS 35-3-12. Exercise Class 1: CSS 15-3-15
- I stream and record all lectures with Zoom (no guarantee that things always work, and the ultimate priority is the crowd on campus!)
- Join online for lectures, exercises, or my office hour on Zoom: [669 9264 2905 (password: 687063)](https://ucph-ku.zoom.us/j/66992642905?pwd=TjViN1VURXlUaUo1SEN5RndOQ1VOUT09)

## This is how the course works

- **Most effort of this course should be spend on \textit{doing} empirical work!**
- Lectures on Monday (even weeks) and every Thursday ([see timetable](https://kurser.ku.dk/course/a%C3%98kk08407u/)): Methods, Theory, state-of-the-art literature
- Lecture plan in Absalon contains weekly coding assignments
- I provide detailed solutions - but you are *strongly recommended* to solve everything on your own
- If you alert me in due time, I will address some exercises or discuss the solutions
- The exercise classes are in the style of open office-hours. Pedro is there to help you - but it is your responsibility to ask if you have questions

The learning curve is very steep, but remember that you can reach out **anytime** in case something is unclear!

## Mandatory Assignments

- 7-day long coding assignments in which we transfer the theory into practice
- The assignments can be written individually or by **groups of a maximum of three students** (you can sign up on the Absalon discussion board if you search for group members)
- You are supposed to hand in one (!) .qmd (Quarto) script with commented source code and one (!) .pdf report in which you describe your methods and results (e.g., with figures, tables, equations, etc.)
- The source code has to create every figure, table, and number used in your report
- **Handed-in report: max. 7 pages for .pdf file in total** (font size 12pt, use [this (click here)](https://github.com/advanced-empirical-finance/course_environment_AEF/tree/main/mandatory_assignments) template)
- All parts must be answered in English
- Be aware of the usual rules for plagiarism and co-written assignments
- *What is the difficulty of mandatory assignments?* I assume that the weekly exercises do not pose any challenge for you anymore

## Mark the dates: Mandatory Assignments

1. mandatory assignment starts **March 1st**
2. mandatory assignment starts **April 12th**
3. mandatory assignment starts **May 3rd**

- The assignments (and data, eventually) will always be uploaded on Absalon
- You will need to unlock the `peergrade` panel once in Absalon
- Deadline: One week to work on your solutions
- Peer feedback opens two days after the submission, and everybody will be asked to provide feedback for two peer assignments individually (subtle hint: this is *one of the most critical steps towards success* - reserve time to give helpful feedback and learn from the answers of your peers)
- The peer feedback period is open for seven days
- **Minimum requirement to get feedback:** Attempt to solve every task. Document your struggles if you do not finish an exercise. The code needs to run without any error or interruption so that your peers can focus on the content instead of fixing your bugs


## Peer feedback
- The mandatory assignments will be available for peer feedback on Absalon
- *Everybody* gets assigned 2 of the peer's submissions for each mandatory assignment (no group work)
- You have one week to provide feedback
- If you receive feedback you feel needs to be drafted more carefully, flag it. Feedback is the most important part of the process, and I will be strict in discarding useless comments

##	Final Exam
- To qualify for the exam, you have to hand in a minimum of two out of the three mandatory assignments *and* provide useful written peer feedback for a minimum of *two* out of the three mandatory assignments to *two* other assignments
- Portfolio exam: **48 hours from XX to XX**
- The exam is a written assignment and consists of two parts: one selected mandatory assignment (you can use the peer feedback to improve your initial submission) and a set of entirely new exercises
- You will hand in a .pdf report and a .qmd file that replicates all results in your report

# Where do we start?

## Your background? Why did you choose to enroll in this course?

![](figures/qr_code.png){width=30% fig-align="center"}

### \textcolor{red}{https://padlet.com/stefanvoigt2/8xyqpu91evwvndss}

1. Bachelor's/Master's/Ph.D. Student?
2. Coding experience (General, R, Python, tidyverse)?
3. General interest in Finance? Data science? Skills for your future career?

# Introduction to R, Python, and Quarto

## This year: Language-agnostic coding

![](figures/paths.jpg){width=30% fig-align="center"}

- Instead of focusing on sharpening your coding skills within Python *or* R, I want to make a case for tidy coding
- We discuss structures of clean, reproducible code that can be achieved using R *and* Python
- Irrespective of your language preferences, code can be readable, understandable, and intuitive as long as you follow standard ground rules


## Why Python and R?

I stick to R or Python (or Julia) because

1. coding languages should be open-source
2. you want an active community of users
3. coding languages should be well-established within the (finance) industry
4. we need communication tools to ensure reproducibility, high-quality visualization, and flexibility for data input and wrangling

Less of an issue

1. Computing speed (unless you want to work in HF or similar fields)

## What is R? Python? Quarto?

- R and Python are languages and environments for statistical computing
- Both are free to download and use / open-source (Users can expand the functionalities through add-ons called packages) / Data processing is easy / Data visualization tools are pervasive
- Python and R are nowadays the de-facto standard tools in Finance (+ you can run Python scripts from within R and vice versa)
- With Quarto you can embed code directly into the analysis. It is easy to share your (reproducible) R and Python output using Quarto

## Why RStudio? Setup for this course

- While *R* and *Python* run computations, *RStudio* is an integrated development environment (IDE) that provides an interface by adding many convenient features and tools
- You can use either Python or R and process your code with Quarto (there will be an asynchronous lecture on how to use Quarto)
- There are solutions to the exercises in both R and Python
- During peer feedback you may receive Python or R submissions - stick to tidy coding principles, and you will be able to understand what the code of your peers is doing even if you are not an expert in their chosen language
- Reversely, that means: Take tidy coding seriously to maximize your chance for valuable feedback
- We will all work in the same environment to ensure your peers can reproduce your results
- Strongly recommend using RStudio as an interface, but you can use other editors

## Getting started with RStudio

![](figures/rstudio.png){width=30% fig-align="center"}

- In case you did not set your environment up yet, follow the Technical Prerequisite section in Absalon:
- [Install R / Install RStudio](https://posit.co/download/rstudio-desktop/#download) / [Install Quarto](https://quarto.org/docs/get-started/) / [clone the course repo](https://github.com/advanced-empirical-finance/aef_environment)

```{r}
#| eval: false
install.packages(reticulate)
reticulate::install_python(version="3.10.11", force = TRUE)
renv::restore() # fetch all R and Python packages required for this courses
```

- If you have never used R or RStudio, Chapters 1-3 of this book are an excellent starting point: [**Basic introduction to R**](https://rstudio-education.github.io/hopr/basics.html)
- Sign up for a [free account at DataCamp](https://app.datacamp.com/groups/advanced-empirical-finance-topics-and-data-science-f01dd0bd-6466-48a1-9af4-009f3f316fe0) (only with econ.ku.dk or alumni.ku.dk address)

## Data science workflow with the tidyverse and pandas / numpy

![](figures/tidyverse_workflow.png){width=60% fig-align="center"}

- The tidyverse is "a framework for managing data that aims at doing the cleaning and preparing steps much easier"
- We work almost exclusively with tidyverse packages: ggplot, dplyr, readr, ...
- [Hadley Wickhams and Garret Grolemunds famous book *R for Data Science*](https://r4ds.hadley.nz/) explains everything we need
- During this semester, we cover almost every topic from their book
- Python equivalent: `pandas`, `numpy`, `plotnine`

## Ready for a first case study in R?

- Start by opening your project or getting the working directory right
```{r}
#| eval: false
setwd("path_to_your_course_folder")
```
- load the package `tidyverse`
- Import data: `read_csv()`, `read_txt()`, .., or download with `tidyquant`
```{r}
library(tidyverse)
library(tidyquant)
prices_raw <- tq_get(c("AAPL", "MSFT"), get = "stock.prices", from = "2000-01-01")
prices_raw # print the object prices_raw in the console
```

- Tidy/Transform, e.g. with `rename()` or `mutate()`
```{r}
prices_tmp <- rename(prices_raw, traded_shares = volume) # Rename volume column name
prices_vol <- mutate(prices_tmp, volume_usd = traded_shares * close) # create a new column
```

## Give your code some air

### Syntax with the pipe `|>` (R) and `.` (Python)

- `verb(subject, complement)` is replaced by `subject |> verb(complement)` (R) or `subject.verb(complement)` (Python)
- No need to name unimportant variables
- Clear readability

```{r}
prices <- prices_raw |>
  rename(traded_shares = volume) |>
  mutate(volume_usd = traded_shares * close / 1000000) # Volume in million USD
prices # Take a glimpse at your data
```

- Do not get confused. Some sources in R use (outdated) `%>%` instead of `|>`!

## The same with Python


- Workhorse packages: `pandas`, `numpy`, and `plotnine`
`
```{python}
import pandas as pd
import numpy as np
from plotnine import *
import yfinance as yf
```

```{python}
prices = (yf.download(tickers=["AAPL", "MSFT"],
                            start="2000-01-01",
                            progress=False)
  .melt(ignore_index=False,
        var_name=["variable", "symbol"])
  .reset_index()
  .pivot(index=["Date", "symbol"],
         columns="variable",
         values="value")
  .reset_index()
  .rename(columns = {"Date": "date",
                     "Volume": "traded_shares",
                     "Close": "close",
                     "Adj Close": "adjusted"})
  .assign(volume_usd = lambda x: x["traded_shares"] * x["close"] / 1000000)
)

prices
```

## Next steps

- Select or drop columns
```{r}
#| eval: false
prices |> select(symbol, date, adjusted) # Only select symbol, date, adjusted
prices |> select(-close) # Drop close price
```

- Working with `date` format
```{r}
prices <- prices |> mutate(year = year(date))
```

- Joining different tables [(too fast? Enjoy this illustration)](https://www.garrickadenbuie.com/project/tidyexplain/#mutating-joins)

```{r}
prices_sp500 <- tq_get("^GSPC", from = "2000-01-01") |> select(date,  market = adjusted)
joint_prices <- left_join(prices, prices_sp500, join_by(date))
joint_prices |> select(symbol, date, adjusted, market)
```

## Basic exploratory data analysis

- `count`, `group_by` and `summarise` solve *many* data science questions
- *How many daily observations per symbol?*
```{r}
prices |> count(symbol)
```

- *Which ticker had the highest average daily volume (in USD)?*

```{r}
average_volume <- prices |>
  group_by(symbol) |>
  summarise(avg_volume = mean(volume_usd))
average_volume |> arrange(desc(avg_volume))
```

## Tidy data: "grammar" of data science workflows

![](figures/tidydata.png){width=40% fig-align="center"}

- Did you ever think about what makes data easy to work with?
- Clear data structure to ensure similar workflows for everyday tasks
- Tidy data is a standard way of mapping the meaning of a dataset to its structure
- In tidy data, each variable forms a column. Each observation forms a row. Each cell is a single measurement

```{r}
avg_vol_ts <- prices |> group_by(year, symbol) |> summarise(avg_volume = mean(volume_usd)) |>
  pivot_wider(names_from = symbol, values_from = avg_volume)
avg_vol_ts # One year per row, two observations per year
```

```{r}
#| output: false
# Back to the initial setup
avg_vol_ts |> pivot_longer(cols = -year, names_to = "symbol", values_to = "avg_volume")
```

## Visualization with the tidyverse: ggplot2

- `ggplot2`: *G*rammar of *g*raphics differentiates between the data and the representation
- Data (data frame being plotted)
- Geometrics (geometric shape that represents the data: point, boxplot, histogram)
- Aesthetics (color, size, shape)

```{r}
ggplot(data = prices_sp500) + aes(x = date, y = market) + geom_line()
```
```{r}
#| eval: false
prices_sp500 |> ggplot() + aes(x = date, y = market) + geom_point()
prices_sp500 |> ggplot() + aes(x = date, y = market) + geom_point(color = "red")
```

## ggplot2 - (Many) other options

```{r}
p <- prices |> ggplot() + aes(x = date, y = volume_usd, color = symbol) +
  geom_point(size = 0.2) + geom_line(linetype = "dotted")

library(scales) # for scale labeling
p + labs(x = "Date", y ="Volume (USD)", title = "Daily volume", color = NULL) +
  facet_wrap(~symbol, scales = "free_x") + theme_tq() +
  scale_y_continuous(labels = scales::unit_format(unit = "M", 
                                                  prefix = "$"))

```

- Many more themes here: https://ggplot2.tidyverse.org/reference/ggtheme.html
- Virtually unlimited possibilities, see [Cedric Scherer's blog](https://cedricscherer.netlify.app/top/dataviz/)

## Tidy coding principles in a nutshell

- Great code is very subjective but the aim should be to make it human-readable
- In this course I want you to think and reflect about *what* makes code useful?

**Core principles to make code readable**

1. chaining ( `|>` or `.`)
1. intuitive naming conventions (`trading_volume_usd` instead of `tmp_Var_2`)
1. Tidy data principles with a clear data structure
1. Embed code directly into the analysis with `Quarto`

### Quarto?

- Suppose you write a seminar paper that requires you to analyze some data such that you can state some summary statistics in your document. \textcolor{red}{How would you do this, typically?}
- You can weave narrative text and code together to produce elegantly formatted output as documents, web pages, blog posts, books, and more
- No more copy-paste, no more manually rebuilding analyses from disparate components, and no more dread when the data is updated and you need to run an analysis

## Language-agnostic tidy coding principles

:::: {.columns}
::: {.column width="45%"}
```{r}
# R
returns <- prices |>
  filter(symbol == "AAPL") |>
  arrange(date) |>
  mutate(ret = adjusted / lag(adjusted) - 1) |>
  select(symbol, date, ret) |>
  drop_na(ret)
returns
```
:::
::: {.column width="45%"}
```{python}
# Python
returns = (prices
  .query('symbol == "AAPL"')
  .sort_values("date")
  .assign(ret = lambda x: x["adjusted"].pct_change())
  .get(["symbol", "date", "ret"])
  .dropna())
returns.head(4)
```
:::
::::

## Language-agnostic visualization with tidy coding principles

:::: {.columns}
::: {.column width="45%"}
```{r}
# R
quantile_05 <- quantile(returns$ret, 
                        probs = 0.05)
returns |>
  ggplot(aes(x = ret)) +
  geom_histogram(bins = 100) +
  geom_vline(aes(xintercept = quantile_05),
    linetype = "dashed") +
  labs(x = NULL, y = NULL,
       title = "Daily Apple stock returns"
  ) +
  scale_x_continuous(labels = percent)

```
:::
::: {.column width="45%"}
```{python}
# Python
quantile_05 = returns["ret"].quantile(0.05)

(ggplot(returns, aes(x="ret")) +
  geom_histogram(bins=100) +
  geom_vline(aes(xintercept=quantile_05),
                 linetype="dashed") +
  labs(x="", y="",
       title="Daily Apple stock returns")
)
```
:::
::::

## The most important slide: How to get help online and from peers

### Try to stick to the following roadmap if you encounter problems

1. If you do not know what a command, e.g., `cov()` is doing, type `help(cov)` in the console
1. Search online, e.g. *R cov* - ChatGPT will know
1. Use the discussion board in Absalon (you are also *very* welcome to provide answers to your questions after they have been solved)
1. Check out the [tidyverse cheatsheets](https://www.rstudio.com/resources/cheatsheets/)

### ChatGPT and Github Copilot

1. I **recommend** using ChatGPT and the like throughout the course for code-related questions
1. I expect that you invest the time you save in making clever use of AI to ensure that your code and assignments are of outstanding quality